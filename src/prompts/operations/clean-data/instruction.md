# Instructions

1. Analyze the <text_input> to understand its structure, data types, and potential issues.

2. If a <main_focus> is provided, prioritize this aspect throughout the cleaning process.

3. Remove duplicate entries:
   - Identify and list all duplicate records in the dataset.
   - Determine the criteria for keeping one record and removing others (e.g., most recent, most complete).
   - Remove the duplicate entries based on the established criteria.

4. Correct errors in the data:
   - Identify common types of errors (e.g., typos, formatting inconsistencies, out-of-range values).
   - List the errors found, categorizing them by type.
   - Apply appropriate correction techniques for each error type.
   - Document the corrections made for transparency.

5. Address missing values:
   - Identify all instances of missing data in the dataset.
   - Determine the most appropriate method for handling each case of missing data (e.g., imputation, deletion, or flagging).
   - Apply the chosen method to address the missing values.
   - Document the approach used for each instance of missing data.

6. Perform a final quality check:
   - Verify that all duplicates have been removed.
   - Ensure all identified errors have been corrected.
   - Confirm that missing values have been appropriately addressed.

7. Summarize the cleaning process:
   - Provide a brief overview of the actions taken.
   - Highlight any significant changes or challenges encountered.
   - If a <main_focus> was specified, emphasize how it was prioritized in the cleaning process.

8. Prepare the cleaned dataset for output, ensuring it maintains its original structure and format where appropriate.
